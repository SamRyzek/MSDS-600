{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165166dd",
   "metadata": {},
   "source": [
    "# DS Automation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195af74",
   "metadata": {},
   "source": [
    "Using our prepared churn data from week 2:\n",
    "- use pycaret to find an ML algorithm that performs best on the data\n",
    "    - Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics.\n",
    "- save the model to disk\n",
    "- create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "    - your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "    - the true values for the new data are [1, 0, 0, 1, 0] if you're interested\n",
    "- test your Python module and function with the new data, new_churn_data.csv\n",
    "- write a short summary of the process and results at the end of this notebook\n",
    "- upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox\n",
    "\n",
    "*Optional* challenges:\n",
    "- return the probability of churn for each new prediction, and the percentile where that prediction is in the distribution of probability predictions from the training dataset (e.g. a high probability of churn like 0.78 might be at the 90th percentile)\n",
    "- use other autoML packages, such as TPOT, H2O, MLBox, etc, and compare performance and features with pycaret\n",
    "- create a class in your Python module to hold the functions that you created\n",
    "- accept user input to specify a file using a tool such as Python's `input()` function, the `click` package for command-line arguments, or a GUI\n",
    "- Use the unmodified churn data (new_unmodified_churn_data.csv) in your Python script. This will require adding the same preprocessing steps from week 2 since this data is like the original unmodified dataset from week 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949c6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff2ff6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>MonthlyCharges_to_tenure_ratio</th>\n",
       "      <th>TotalCharges_to_tenure_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7590-VHVEG</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.033501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575-GNVDE</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.017994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668-QPYBK</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037140</td>\n",
       "      <td>0.018493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795-CFOCW</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>0.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237-HQITU</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028289</td>\n",
       "      <td>0.013188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "customerID                                                                  \n",
       "7590-VHVEG       1             1         0              0           29.85   \n",
       "5575-GNVDE      34             0         1              1           56.95   \n",
       "3668-QPYBK       2             0         0              1           53.85   \n",
       "7795-CFOCW      45             1         1              2           42.30   \n",
       "9237-HQITU       2             0         0              0           70.70   \n",
       "\n",
       "            TotalCharges  Churn  MonthlyCharges_to_tenure_ratio  \\\n",
       "customerID                                                        \n",
       "7590-VHVEG         29.85      1                        0.033501   \n",
       "5575-GNVDE       1889.50      1                        0.597015   \n",
       "3668-QPYBK        108.15      0                        0.037140   \n",
       "7795-CFOCW       1840.75      1                        1.063830   \n",
       "9237-HQITU        151.65      0                        0.028289   \n",
       "\n",
       "            TotalCharges_to_tenure_ratio  \n",
       "customerID                                \n",
       "7590-VHVEG                      0.033501  \n",
       "5575-GNVDE                      0.017994  \n",
       "3668-QPYBK                      0.018493  \n",
       "7795-CFOCW                      0.024447  \n",
       "9237-HQITU                      0.013188  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Assignment/data/prepped_churn_data.csv\", index_col='customerID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a28a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7032 entries, 7590-VHVEG to 3186-AJIEK\n",
      "Data columns (total 9 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   tenure                          7032 non-null   int64  \n",
      " 1   PhoneService                    7032 non-null   int64  \n",
      " 2   Contract                        7032 non-null   int64  \n",
      " 3   PaymentMethod                   7032 non-null   int64  \n",
      " 4   MonthlyCharges                  7032 non-null   float64\n",
      " 5   TotalCharges                    7032 non-null   float64\n",
      " 6   Churn                           7032 non-null   int64  \n",
      " 7   MonthlyCharges_to_tenure_ratio  7032 non-null   float64\n",
      " 8   TotalCharges_to_tenure_ratio    7032 non-null   float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 549.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b529aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a53bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('Churn', axis=1)\n",
    "targets = df['Churn']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, targets, stratify=targets, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67f467f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6402b946ca7b4237b3aac6a9cba0b158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7965504465048519\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7967416387132746\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7967416387132746\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7967416387132746\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7967416387132746\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=False, criterion=entropy, max_features=0.25, min_samples_leaf=10, min_samples_split=5, n_estimators=100)\n",
      "0.7986348122866894\n",
      "CPU times: total: 52 s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, cv=5, random_state=42, scoring='accuracy', verbosity=2, n_jobs=-1)\n",
    "tpot.fit(x_train,y_train)\n",
    "print(tpot.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711a176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tpot.predict(x_test)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d6da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurace of TPOT predictions: 0.7986348122866894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Accurace of TPOT predictions: {accuracy_score(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db425dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.decomposition</span> <span class=\"kn\">import</span> <span class=\"n\">PCA</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">make_pipeline</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.tree</span> <span class=\"kn\">import</span> <span class=\"n\">DecisionTreeClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.export_utils</span> <span class=\"kn\">import</span> <span class=\"n\">set_param_recursive</span>\n",
       "\n",
       "<span class=\"c1\"># NOTE: Make sure that the outcome column is labeled &#39;target&#39; in the data file</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;../Assignment/data/new_churn_data.csv&#39;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;customerID&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">testing_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">,</span> <span class=\"n\">testing_target</span> <span class=\"o\">=</span> \\\n",
       "            <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">tpot_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">],</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Average CV score on the training set was: 0.7967416387132746</span>\n",
       "<span class=\"n\">exported_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">make_pipeline</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">PCA</span><span class=\"p\">(</span><span class=\"n\">iterated_power</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">svd_solver</span><span class=\"o\">=</span><span class=\"s2\">&quot;randomized&quot;</span><span class=\"p\">),</span>\n",
       "    <span class=\"n\">DecisionTreeClassifier</span><span class=\"p\">(</span><span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"s2\">&quot;entropy&quot;</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">9</span><span class=\"p\">,</span> <span class=\"n\">min_samples_leaf</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">min_samples_split</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">)</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"c1\"># Fix random state in exported estimator</span>\n",
       "<span class=\"n\">set_param_recursive</span><span class=\"p\">(</span><span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">steps</span><span class=\"p\">,</span> <span class=\"s1\">&#39;random_state&#39;</span><span class=\"p\">,</span> <span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{decomposition} \\PY{k+kn}{import} \\PY{n}{PCA}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{pipeline} \\PY{k+kn}{import} \\PY{n}{make\\PYZus{}pipeline}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{tree} \\PY{k+kn}{import} \\PY{n}{DecisionTreeClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{export\\PYZus{}utils} \\PY{k+kn}{import} \\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} NOTE: Make sure that the outcome column is labeled \\PYZsq{}target\\PYZsq{} in the data file}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{../Assignment/data/new\\PYZus{}churn\\PYZus{}data.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{customerID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{testing\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{,} \\PY{n}{testing\\PYZus{}target} \\PY{o}{=} \\PYZbs{}\n",
       "            \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{tpot\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Average CV score on the training set was: 0.7967416387132746}\n",
       "\\PY{n}{exported\\PYZus{}pipeline} \\PY{o}{=} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{(}\n",
       "    \\PY{n}{PCA}\\PY{p}{(}\\PY{n}{iterated\\PYZus{}power}\\PY{o}{=}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{n}{svd\\PYZus{}solver}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{randomized}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{n}{DecisionTreeClassifier}\\PY{p}{(}\\PY{n}{criterion}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{entropy}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{max\\PYZus{}depth}\\PY{o}{=}\\PY{l+m+mi}{9}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}leaf}\\PY{o}{=}\\PY{l+m+mi}{2}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}split}\\PY{o}{=}\\PY{l+m+mi}{12}\\PY{p}{)}\n",
       "\\PY{p}{)}\n",
       "\\PY{c+c1}{\\PYZsh{} Fix random state in exported estimator}\n",
       "\\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\\PY{p}{(}\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{steps}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{random\\PYZus{}state}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{)}\n",
       "\\PY{n}{results} \\PY{o}{=} \\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{predict}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\n",
       "\\PY{n+nb}{print}\\PY{p}{(}\\PY{n}{results}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "from sklearn.decomposition import PCA\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.pipeline import make_pipeline\n",
       "from sklearn.tree import DecisionTreeClassifier\n",
       "from tpot.export_utils import set_param_recursive\n",
       "\n",
       "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
       "tpot_data = pd.read_csv('../Assignment/data/new_churn_data.csv')\n",
       "tpot_data = tpot_data.drop('customerID', axis=1)\n",
       "features = tpot_data.drop('target', axis=1)\n",
       "training_features, testing_features, training_target, testing_target = \\\n",
       "            train_test_split(features, tpot_data['target'], random_state=42)\n",
       "\n",
       "# Average CV score on the training set was: 0.7967416387132746\n",
       "exported_pipeline = make_pipeline(\n",
       "    PCA(iterated_power=8, svd_solver=\"randomized\"),\n",
       "    DecisionTreeClassifier(criterion=\"entropy\", max_depth=9, min_samples_leaf=2, min_samples_split=12)\n",
       ")\n",
       "# Fix random state in exported estimator\n",
       "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
       "\n",
       "exported_pipeline.fit(training_features, training_target)\n",
       "results = exported_pipeline.predict(testing_features)\n",
       "\n",
       "print(results)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "Code('tpot_churn_pipeline_processed.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee13ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Predictions\n",
      "[1 1 0 ... 1 0 1]\n",
      "Actuals\n",
      "customerID\n",
      "0394-YONDK    1\n",
      "6933-VLYFX    1\n",
      "9360-OMDZZ    1\n",
      "7912-SYRQT    0\n",
      "7191-ADRGF    1\n",
      "             ..\n",
      "3552-CTCYF    1\n",
      "5915-ANOEI    1\n",
      "7994-XIRTR    1\n",
      "9172-ANCRX    0\n",
      "3551-GAEGL    1\n",
      "Name: Churn, Length: 1758, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Churn Predictions')\n",
    "print(predictions)\n",
    "print('Actuals')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b848b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_churn_pipeline_raw.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40870395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1997dba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "%run try2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea508aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "%run tpot_churn_pipeline_processed.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49db562",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533a1cd",
   "metadata": {},
   "source": [
    "Write a short summary of the process and results here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf273de3",
   "metadata": {},
   "source": [
    "Ok this assignment confused me quite a bit. I believe the overall objective was to build a predictive model and apply it to a new data set. So for my assignment I used tpot and built my model and generated my python program. This is where things kind of fell apart for me and based off of our discussion in class it sounded like quite a few other struggled as well. But here is a break-down of what I did and the decision I made. So the first thing I did was to modify my raw pipeline code to take in a new churn data set with a target variable. I assume at this point that the target variable here is supposed to mimic Churn data. There was a not on the example that stated that we need to make the dataset meet the format of our existing data set. This is where I got confused. Our existing dataset had Churn data in it, the new dataset did not. So, I added the data to the new data set based on the information that was given as part of the assignment. The code would not run without target data. This did not feel right and I am not sure this was the proper way to handle it, and I look forward to seeing the solution to see if I was close or how to properly do this. I then ran the newly created python script against the new data set and returned the resultant predictions. I did this with two different python scripts. The first was taked after the example given in the course work, the second closely resembled the generated python script that came from tpot. Both generated the exact same result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
